{"title":"AI ที่อธิบายได้: หลักการ เหตุผล และความจำเป็น","link":"https://srakrn.me/blog/explainable-ai/","date":1586581994000,"content":"<div id=\"readability-page-1\" class=\"page\"><a href=\"#content\">Skip to content</a><div id=\"boxed-wrapper\"><header><div><nav aria-label=\"Main Menu\"><ul id=\"menu-menu\"><li id=\"menu-item-327\" data-item-id=\"327\"><a href=\"https://srakrn.me/blog/my-reading-list/\"><span>My Reading List</span></a></li><li id=\"menu-item-328\" data-item-id=\"328\"><a href=\"https://srakrn.me/blog/my-wishlist/\"><span>My Wishlist</span></a></li></ul></nav><nav aria-label=\"Main Menu Mobile\"></nav></div></header><div><h2>AI ที่อธิบายได้: หลักการ เหตุผล และความจำเป็น</h2></div><main id=\"main\"><section id=\"content\"><article id=\"post-1079\"><span>AI ที่อธิบายได้: หลักการ เหตุผล และความจำเป็น</span><div><p><em>รวมบทความในชุดดังกล่าวที่เผยแพร่ครั้งแรกบนเฟซบุ๊กของศิระกร ลำใย, บทความขณะนี้ยังเขียนไม่ครบทุกตอน</em></p><h2>ทำไมเราต้องมี AI ที่อธิบายได้</h2><p>(1)</p><figure><img src=\"https://srakrn.me/blog/wp-content/uploads/2020/04/Slide1-1024x576.png\" alt=\"\" srcset=\"https://srakrn.me/blog/wp-content/uploads/2020/04/Slide1-300x169.png 300w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide1-768x432.png 768w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide1-1024x576.png 1024w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide1-1100x619.png 1100w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide1.png 1280w\" sizes=\"(max-width: 1024px) 100vw, 1024px\"><figcaption><br>จำนวนร้อยละของผู้ต้องหาที่ได้รับการปล่อยตัวระหว่างสู้คดี โดยที่ไม่ต้องวางเงินประกันตัว ในช่วงเวลาต่างๆ ของปี สังเกตว่าช่องว่างระหว่างจำนวนผู้ต้องหาผิวสีและผู้ต้องหาผิวขาวเพิ่มขึ้นอย่างมากหลังการประกาศใช้กฎหมาย HB463<br>ภาพประกอบทำซ้ำจาก <a href=\"https://www.minnesotalawreview.org/wp-content/uploads/2019/01/13Stevenson_MLR.pdf\">https://www.minnesotalawreview.org/wp-content/uploads/2019/01/13Stevenson_MLR.pdf</a></figcaption></figure><p>ในปี 2017 รัฐเคนตักกี้ผ่านร่างกฎหมาย HB417 ที่บังคับให้ผู้พิพากษาต้องปรึกษากับระบบอัตโนมัติเพื่อพิจารณาว่าผู้ต้องหาที่จะได้รับการประกันตัวหรือปล่อยตัวระหว่างสู้คดี จะสร้างความอันตรายให้กับสาธารณะหรือไม่</p><p>หลังจากร่างกฎหมายดังกล่าวผ่าน ช่องว่างระหว่างจำนวนคนขาวและคนผิวสีที่ได้รับการประกันตัวพุ่งสูงขึ้นมาก [ภาพที่ 1] คนผิวขาวได้รับการปล่อยตัวโดยไม่ต้องวางเงินประกันเพิ่มขึ้น ขณะที่คนผิวสีไม่ได้รับการปล่อยตัวในลักษณะเดียวกันมากขึ้นเท่าไหร่นัก</p><p>(2)</p><figure><img src=\"https://scontent.fbkk5-7.fna.fbcdn.net/v/t1.0-9/92429908_614615002461808_3275585606050119680_n.jpg?_nc_cat=104&amp;_nc_sid=8024bb&amp;_nc_eui2=AeH5B2TV036L7SOGfev8BCZdx6CqI5ppTvvHoKojmmlO-4hSYKYJptXRS4F9Bw0Jw4rr_iXccnUMWviGX-GOry7z&amp;_nc_ohc=BNPU-FvtZY0AX9wsBIC&amp;_nc_ht=scontent.fbkk5-7.fna&amp;oh=e5d14287d0c45b42211aef1d21fd55cc&amp;oe=5EB63F59\" alt=\"No photo description available.\"><figcaption>อัตราการจ้างงานในสายเทคโนโลยีของบริษัทชั้นนำในสหรัฐ<br>ภาพประกอบทำซ้ำจาก <a href=\"https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G\">https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G</a></figcaption></figure><p>ในปี 2018 แอมะซอน “โละ” ระบบคัดกรองใบสมัครงานทิ้ง ระบบนี้เกิดขึ้นมาเพื่อคาดหวังว่าจะช่วยกรองใบสมัครงานที่ได้รับเข้ามาเป็นพันๆ ใบเพื่อช่วยลดงานของมนุษย์ เหตุผลของการโละระบบคัดกรองดังกล่าวคือ ข้อมูลการรับสมัครงานที่ใช้ในการ “สอน” ระบบมีจำนวนเพศชายมากกว่าเพศหญิง [ภาพที่ 2] เมื่อระบบดังกล่าวถูกสอนด้วยข้อมูลลักษณะเช่นนี้ ก็จะหยิบเอาพฤติกรรมการเลือกผู้สมัครชายมากกว่าผู้สมัครหญิงมามากขึ้นเช่นกัน</p><p>(3)</p><figure><img src=\"https://srakrn.me/blog/wp-content/uploads/2020/04/Slide2.png\" alt=\"\" srcset=\"https://srakrn.me/blog/wp-content/uploads/2020/04/Slide2-300x169.png 300w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide2-768x432.png 768w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide2-1024x576.png 1024w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide2-1100x619.png 1100w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide2.png 1280w\" sizes=\"(max-width: 1280px) 100vw, 1280px\"></figure><p>หนึ่งในเครื่องมือประมวลผลภาษาธรรมชาติ (NLP) ที่ได้รับความนิยม คือการเปลี่ยนคำเป็นเลขที่มีความหมาย เรียกว่าการทำ word embedding การเปลี่ยนคำเป็นเลขทำให้เราใช้วิธีการทางคณิตศาสตร์ในการสอนคอมพิวเตอร์แก้โจทย์เชาว์ในลักษณะ “กรุงเทพคู่กับประเทศไทย เหมือนที่ลอนดอนคู่กัน ___” ได้</p><p>ถ้าเราถามคำถามลักษณะเดียวกันเช่น “ชายคู่กับพ่อ เหมือนหญิงคู่กับ ___”, “ชายคู่กับราชา เหมือนหญิงคู่กับ ___”, “ชายคู่กับหมอ เหมือนหญิงคู่กับ ___”, “ชายคู่กับฟุตบอล เหมือนหญิงคู่กับ ___” เราจะพบว่าบางครั้งคู่คำไม่สามารถเติมได้ (เช่นหมอ เพราะผู้หญิงก็เป็นหมอได้ และเราก็มีบุรุษพยาบาล) แต่อคติและความโน้มเอียงทางเพศที่ถูกสื่อผ่านงานเขียนและข้อมูลที่ใช้ “สอน” ตัวเปลี่ยนคำให้เป็นเลข ก็ทำให้คอมพิวเตอร์ตอบคำถามเหล่านี้แบบโน้มเอียงทางเพศไม่ใช่น้อย [ภาพที่ 3]</p><p>ด้วยตัวอย่างที่เกิดขึ้นจริงบนโลก และสร้างผลกระทบไว้แล้วไม่ใช่น้อย เราควรจะเห็นว่า AI ไม่ใช่ของวิเศษที่จะอ้างว่าเอามาใช้แล้วจบ กระบวนการสอน AI ให้มีความฉลาดในการทำงาน โดยเฉพาะในงานที่มีความสำคัญ จำเป็นต้องผ่านการตรวจสอบอคติใน AI เป็นอย่างละเอียด ขั้นตอนวิธีดังกล่าวไม่ใช่เรื่องง่าย แต่หากไม่สามารถการันตีได้ว่า AI ผ่านการตรวจสอบแล้ว การใช้ AI ก็ย่อมไม่ก่อให้เกิดประโยชน์นอกจากการทุ่นเวลาที่มาพร้อมกับข้อเสียมหาศาลและความกังขาในการอธิบายไม่ได้ที่จะเกิดขึ้นจำนวนมาก</p><hr><h2>AI ไม่ใช่พ่อ และความผิดพลาดของ AI ก็ต้องอธิบายได้</h2><p>ก่อนพูดถึงความจำเป็นในการอธิบาย AI เราอาจจะต้องย้อนไปถึงการอธิบายการบอกว่า AI ทำงานได้ดีแค่ไหนในกรณีทั่วไปก่อน สำหรับโครงการเราไม่ทิ้งกัน แน่นอนว่าสิ่งที่เราอยากทำคือการตอบว่า “ใช่ (+)” หรือ “ไม่ (-)” สำหรับคำถามว่าเราควรแจกเงินคนคนนี้หรือเปล่า</p><figure><img src=\"https://srakrn.me/blog/wp-content/uploads/2020/04/Slide7.png\" alt=\"\" srcset=\"https://srakrn.me/blog/wp-content/uploads/2020/04/Slide7-300x169.png 300w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide7-768x432.png 768w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide7-1024x576.png 1024w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide7-1100x619.png 1100w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide7.png 1280w\" sizes=\"(max-width: 1280px) 100vw, 1280px\"></figure><p>กรณีที่เกิดขึ้นกับคำตอบเป็นไปได้สี่แบบ</p><ul><li>บวกจริง (ดูจากสภาพแล้วควรได้เงินจริงๆ และ AI ก็ตอบว่าใช่ ควรได้เงิน)</li><li>บวกลวง (ดูจากสภาพแล้วไม่ควรได้เงิน แต่ AI กลับตอบว่าใช่ ควรได้เงิน)</li><li>ลบลวง (ดูจากสภาพแล้วควรได้เงินจริงๆ แต่ AI กลับตอบว่าไม่ต้องให้เงินคนนี้)</li><li>ลบจริง (ดูจากสภาพแล้วไม่ควรได้เงิน และ AI ก็ตอบว่าไม่ต้องให้เงินคนนี้)</li></ul><p>ถ้าเราเป็นรัฐบาลที่กำลังถังแตก เราอาจจะบอกว่าแจกเงินตกหล่นไปบ้างไม่เป็นไร แต่เงินทุกบาทต้องไปถึงมือคนที่ต้องการ “จริง” แต่ถ้าเราเงินเหลือ เราอาจจะบอกว่าเผลอแจกเงินคนไม่เดือดร้อนก็ได้ เซฟไว้หน่อย เงินจะได้ถึงมือคนครบๆ แน่นอนว่าปัญหาในลักษณะนี้ไม่ได้เป็นปัญหาแค่ในเชิง AI–ยกตัวอย่างง่ายๆ ตอนนี้กระทรวงสาธารณสุขกำหนดว่าจะส่งตรวจ COVID-19 ได้ ผู้ป่วยต้องมีเกณฑ์อะไรบ้าง–ลองคิดสภาพว่ากฎประมาณนี้เกิดมาจากการเนรมิตของ AI แล้วเราเห็นอะไรบ้าง</p><figure><img src=\"https://srakrn.me/blog/wp-content/uploads/2020/04/Slide3-1-1024x576.png\" alt=\"\" srcset=\"https://srakrn.me/blog/wp-content/uploads/2020/04/Slide3-1-300x169.png 300w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide3-1-768x432.png 768w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide3-1-1024x576.png 1024w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide3-1-1100x619.png 1100w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide3-1.png 1280w\" sizes=\"(max-width: 1024px) 100vw, 1024px\"></figure><p>เราน่าจะเคยเห็นหลายๆ เคสของผู้ป่วยที่ไม่มีไข้ แต่ส่งตรวจเองแล้วผลเป็นบวก พอมามองเกณฑ์นี้ก็จะเห็นว่ามีผู้ป่วยที่น่าจะถูกปัดตกโดยเกณฑ์ไปจากการที่วัดไข้แล้วไม่เจอ ในกรณีนี้ เราสามารถไปไล่ตั้งคำถามได้ทันทีว่าทำไมผู้ป่วยคนนีัถึงไม่ถูกตรวจทั้งๆ ที่ควรจะตรวจ แล้วค่อยๆ ปรับเกณฑ์กันไป</p><p>แต่สิ่งเหล่านี้จะไม่เกิดขึ้นกับ AI ที่อธิบายไม่ได้–AI หลายครั้งทำหน้าที่เป็นเหมือนกล่องดำ ยัดข้อมูลเข้าไปแล้วได้คำตอบ แต่ไม่มีคำอธิบายว่าทำไมถึงออกมาเป็นแบบนี้ ซ้ำร้ายในหลายๆ แบบจำลอง การ “แงะ” กล่องดำมาดูว่าทำไมถึงเป็นแบบนี้ ยิ่งไม่สามารถทำได้ด้วยซ้ำ</p><p>แต่สิ่งเหล่านี้จะไม่เกิดขึ้นกับ AI ที่อธิบายไม่ได้–AI หลายครั้งทำหน้าที่เป็นเหมือนกล่องดำ ยัดข้อมูลเข้าไปแล้วได้คำตอบ แต่ไม่มีคำอธิบายว่าทำไมถึงออกมาเป็นแบบนี้ ซ้ำร้ายในหลายๆ แบบจำลอง การ “แงะ” กล่องดำมาดูว่าทำไมถึงเป็นแบบนี้ ยิ่งไม่สามารถทำได้ด้วยซ้ำ</p><figure><img src=\"https://srakrn.me/blog/wp-content/uploads/2020/04/Slide4.png\" alt=\"\" srcset=\"https://srakrn.me/blog/wp-content/uploads/2020/04/Slide4-300x169.png 300w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide4-768x432.png 768w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide4-1024x576.png 1024w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide4-1100x619.png 1100w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide4.png 1280w\" sizes=\"(max-width: 1280px) 100vw, 1280px\"></figure><p>แถมต่อให้บอกว่า AI แม่นจริงๆ สมมติว่าเรามี AI หนึ่งตัวสำหรับใช้คัดกรองโรคที่มีโอกาสพบเจอได้ใน 1% ของประชากร ถ้าสมมติว่าเราให้ AI ตัวนั้นตอบว่า “ไม่เป็น” ไม่ว่าจะกรณีใดๆ ก็ตาม เราจะได้ AI ที่มีความแม่นยำ 99% (เพราะโอกาสที่จะเจอคนไม่เป็นมี 99%)</p><p>คำถามคือเราอยากได้ AI แบบนี้ไหม? แน่นอน คำตอบก็คงเป็นไม่ และถ้าเอา AI แบบนี้มาใช้แจกเงิน รัฐก็คงไม่อยากได้ AI ที่เลือกจะแจกเงินให้ทุกคน หรือเลือกที่จะไม่แจกเงินให้ใครเลย</p><p>ดังนั้น AI ที่ทำงานบนข้อมูลที่มีความละเอียดอ่อน และต้องการความละเอียดอ่อนในการจำแนกปัญหา จึงจำเป็นจะต้องถูกวัดผลอย่างเคร่งครัด และการวัดผลไม่ใช่พึงกระทำแค่การวัดว่าตอบถูกมากน้อย หยิบขาดหยิบเกิน แต่การ “แงะกล่องดำ” มาอธิบายพฤติกรรมนิสัยของ AI ได้ ก็เป็นเรื่องที่จำเป็นไม่แพ้กัน</p><hr><h2>สิทธิ์แห่งคำอธิบาย</h2><figure><img src=\"https://srakrn.me/blog/wp-content/uploads/2020/04/image-1.png\" alt=\"\" srcset=\"https://srakrn.me/blog/wp-content/uploads/2020/04/image-1-300x169.png 300w, https://srakrn.me/blog/wp-content/uploads/2020/04/image-1-768x432.png 768w, https://srakrn.me/blog/wp-content/uploads/2020/04/image-1-1024x576.png 1024w, https://srakrn.me/blog/wp-content/uploads/2020/04/image-1-1100x619.png 1100w, https://srakrn.me/blog/wp-content/uploads/2020/04/image-1.png 1920w\" sizes=\"(max-width: 1920px) 100vw, 1920px\"><figcaption>การชี้แจงสาเหตุการไม่อนุมัติสินเชื่อ ทำซ้ำจาก <a href=\"https://www.bot.or.th/Thai/fipcs/Documents/FPG/2553/ThaiPDF/25530010.pdf\">https://www.bot.or.th/Thai/fipcs/Documents/FPG/2553/ThaiPDF/25530010.pdf</a></figcaption></figure><p>ทุกครั้งเวลาเดินเข้าไปในธนาคารและขอสินเชื่อไม่ผ่าน ธนาคารแห่งประเทศไทยกำหนดให้ธนาคารต้องชี้แจงเหตุผลในการปฏิเสธสินเชื่อ เราจะเข้าใจตัวเองมากขึ้นว่าเพราะอะไรสินเชื่อเราถึงไม่ผ่านการขอ</p><p>หรือหากเราได้รับคำอธิบายว่า “เพราะติดเครดิตบูโร” ในทางเดียวกันเราสามารถส่งคำต้องไปยังบริษัทข้อมูลเครดิตแห่งชาติ เพื่อดูชุดของข้อมูลที่ถูกใช้ปฏิเสธสินเชื่อเราได้ว่ามีความถูกต้องมากน้อยเพียงใด</p><p>นี่คือคำอธิบาย ไม่ใช่เพียงคำอธิบายว่าทำไมสินเชื่อถึงกู้ไม่ผ่าน แต่เป็นคำอธิบายว่าเพราะอะไรเราถึงน่าเชื่อถือหรือไม่น่าเชื่อถือในสายตาสถาบันการเงิน</p><figure><img src=\"https://srakrn.me/blog/wp-content/uploads/2020/05/92555439_615220729067902_8154642920725544960_o-1024x576.jpg\" alt=\"\" srcset=\"https://srakrn.me/blog/wp-content/uploads/2020/05/92555439_615220729067902_8154642920725544960_o-300x169.jpg 300w, https://srakrn.me/blog/wp-content/uploads/2020/05/92555439_615220729067902_8154642920725544960_o-768x432.jpg 768w, https://srakrn.me/blog/wp-content/uploads/2020/05/92555439_615220729067902_8154642920725544960_o-1024x576.jpg 1024w, https://srakrn.me/blog/wp-content/uploads/2020/05/92555439_615220729067902_8154642920725544960_o-1100x619.jpg 1100w, https://srakrn.me/blog/wp-content/uploads/2020/05/92555439_615220729067902_8154642920725544960_o.jpg 1920w\" sizes=\"(max-width: 1024px) 100vw, 1024px\"><figcaption><br>ทำซ้ำจาก <a href=\"https://www.privacy-regulation.eu/en/r71.htm\">https://www.privacy-regulation.eu/en/r71.htm</a></figcaption></figure><p>ใน Recital 71 ของกฎหมาย GDPR (General Data Protection Regulation) ว่าด้วยการคุ้มครองข้อมูลส่วนบุคคล มีการกล่าวถึง “สิทธิ์ในคำอธิบาย” ไว้ว่าผู้ถือครองข้อมูลมีสิทธิ์ที่จะร้องขอให้มนุษย์เข้าแทรกแซงระบบอัตโนมัติใดๆ เพื่อแสดงจุดยืนของตัวเอง และเพื่อร้องขอคำอธิบายเหตุผลของการตัดสินใจ</p><p>จะเห็นได้ว่าปัญหาของอคติจากระบบตัดสินใจอัตโนมัติไม่ใช่ปัญหาที่เพิ่งมีแต่อย่างใด (GDPR ออกเมื่อปี 2016 มีผลบังคับใช้ 2018) แม้จะมีข้อวิพากษ์ว่ากฎหมายลักษณะนี้อาจเอื้อให้เกิดการใช้มนุษย์มากกว่าระบบอัตโนมัติ แต่มุมมองส่วนตัวของผู้เขียนคือตราบใดที่ระบบอัตโนมัติไม่สามารถออกมาอธิบายตัวเองได้ว่าเพราะอะไรจึงตอบแบบนี้ มนุษย์ (ซึ่งอย่างน้อยก็ยังออกมาบอกได้ว่าตัวเองคิดอะไรอยู่–ซึ่งเอื้อให้เกิดการโต้แย้งทั้งความผิดพลาดในการตัดสินใจไม่ว่าโดยสุจริตหรือโดยทุจริต) ก็คงเหมาะกับงานในลักษณะแบบนี้มากกว่าอยู่ดี</p><h2>อคติ อคติ อคติ</h2><h3>ว่าด้วยอคติจากมนุษย์</h3><p>หนึ่งในวิธีการฝึกสอน AI ที่ทำได้ และทำง่าย คือการฝึกสอนแบบมีการควบคุม (supervised learning) ถ้าเราต้องการฝึกสอน AI ให้ตอบว่าจะแจกเงินหรือไม่แจกเงิน เรานำรายการของคนมาตอบเองก่อนว่าจะแจกเงินหรือไม่แจก แล้วให้ AI เรียนรู้รูปแบบการตอบของเราเอง</p><p>ดังนั้นขั้นตอนแรกของการฝึกสอน คือเราจำเป็นต้องแปะป้ายก่อนว่าเราจะแจกเงินใคร และไม่แจกเงินใคร</p><p>เราต้องการแจกเงินคนแบบไหนนะ? คนจนคนเดือดร้อน!คนแบบไหนที่เดือดร้อนนะ? ลูกจ้างรายวัน พนักงานโรงแรม ช่างเสริมสวย แม่ค้า คนขับรถแท็กซี่ พนักงานบริษัท!<br>คนแบบไหนที่ไม่เดือดร้อน* นะ? เด็กอายุต่ำกว่า 18 เกษตรกร นิสิต ขายของออนไลน์ โปรแกรมเมอร์ แรงงานก่อสร้าง!</p><p>แล้วทำไมเราถึงคิดว่าคนแบบนี้เดือดร้อน หรือคนแบบนี้ไม่เดือดร้อน? เพราะเรากำลังใส่สิ่งที่เรียกว่า “อคติ” ลงไป</p><hr><div><figure><img src=\"https://srakrn.me/blog/wp-content/uploads/2020/05/92869186_615233072400001_3284979416786010112_n.jpg\" alt=\"\"></figure></div><p>อคติในที่นี้ไม่ใช่ศัพท์แง่ลบ แต่เป็นการแปลตรงตัวของคำว่า “bias” ในภาษาอังกฤษ<br>มนุษย์เป็นสิ่งมีชีวิตที่เต็มไปด้วยอคติ บ้างจากสัญชาติญาณ บ้างจากประสบการณ์เรียนรู้ หนึ่งในกรณีที่โด่งดังคือภาพหลุมบนดาวอังคารที่ถูกถ่ายจากยานไวกิ้งที่เหมือนหน้าคน แต่ความจริงแล้วเกิดจากการที่เราถูก “อคติ” ของการมองเห็นอะไรเป็นหน้าคนได้เรื่อยๆ เหนี่ยวนำให้เห็นแสงและเงาเป็นหน้าคนไปเองต่างหาก</p><figure><img src=\"https://srakrn.me/blog/wp-content/uploads/2020/04/image-6.png\" alt=\"\" srcset=\"https://srakrn.me/blog/wp-content/uploads/2020/04/image-6-300x169.png 300w, https://srakrn.me/blog/wp-content/uploads/2020/04/image-6-768x432.png 768w, https://srakrn.me/blog/wp-content/uploads/2020/04/image-6-1024x576.png 1024w, https://srakrn.me/blog/wp-content/uploads/2020/04/image-6-1100x619.png 1100w, https://srakrn.me/blog/wp-content/uploads/2020/04/image-6.png 1920w\" sizes=\"(max-width: 1920px) 100vw, 1920px\"><figcaption>Icons made by <a href=\"https://www.flaticon.com/authors/smalllikeart\">smalllikeart</a> from <a href=\"https://www.flaticon.com/\">www.flaticon.com</a></figcaption></figure><p>สำหรับคนที่มีหน้าที่ “แปะป้าย” ข้อมูลสำหรับสอน AI อคติตรงนี้อาจเหนี่ยวนำให้เราคิดว่าโปรแกรมเมอร์เป็นอาชีพที่มีความยืดหยุ่นในการทำงาน (?) ทำจากที่ไหนก็ได้ (?!) หรืออคติว่าเพราะงานก่อสร้างยังไม่ได้รับผลกระทบ กรรมกรก่อสร้างก็เลยไม่ได้รับผลกระทบจาก COVID-19 (?!?!)</p><p>นี่คืออคติรูปแบบที่หนึ่ง เป็นอคติที่เรามองเห็น และเข้าใจได้</p><p>ความน่ากลัวคือแบบจำลองอาจ–จริงๆ ก็ไม่อาจ มีแนวโน้มสูงมากที่–จะ “หยิบ” อคติของมนุษย์ติดตัวเข้ามาด้วย ถ้าอคตินั้นมองเห็นได้ง่ายแบบที่เรามองเห็นวาเกณฑ์อาชีพที่ไม่เข้าข่ายนั้นไม่มีเหตุผล ก็อาจจะรอดตัวไป แต่คนแปะป้ายอาจจะมีอคติอีกจำนวนมากที่เกิดขึ้นโดยไม่รู้ตัว</p><hr><figure><img src=\"https://srakrn.me/blog/wp-content/uploads/2020/04/image-5.png\" alt=\"\" srcset=\"https://srakrn.me/blog/wp-content/uploads/2020/04/image-5-300x169.png 300w, https://srakrn.me/blog/wp-content/uploads/2020/04/image-5-768x432.png 768w, https://srakrn.me/blog/wp-content/uploads/2020/04/image-5-1024x576.png 1024w, https://srakrn.me/blog/wp-content/uploads/2020/04/image-5-1100x619.png 1100w, https://srakrn.me/blog/wp-content/uploads/2020/04/image-5.png 1920w\" sizes=\"(max-width: 1920px) 100vw, 1920px\"></figure><p>ขออนุญาตเล่านิทานเรื่องลูกเป็ดขี้เหร่ มีลูกเป็ดตัวนึงขี้เหร่ โตมากลายเป็นหงส์ จบ</p><p>เดี๋ยว ทำไมลูกเป็ดถึงขี้เหร่นะ–เพราะมันมีสีดำ, แล้วลูกเป็ดตัวอื่นขี้เหร่ไม่ได้เหรอ</p><p>สมมติว่าผมมีลูกเป็ดสามตัว ว่ายน้ำเรียงกันต้อยๆ ถ้าผมพิจารณาการถามเพียงว่า “ลูกเป็ดตัวนี้ใช่ตัวหน้าสุดไหม” กับ “ลูกเป็ดตัวนี้ใช่สีดำไหม” ผมสามารถเขียนกฎออกมาเพื่อ “เลือก” แปะป้ายลูกเป็ดตัวไหนก็ได้ว่าเป็นลูกเป็ดขี้เหร่ เช่นถ้าผมบอกว่า “ลูกเป็ดที่ไม่ได้เป็นตัวหน้าและไม่ได้เป็นสีดำ เป็นลูกเป็ดขี้เหร่” ตัวตรงกลางก็จะกลายเป็นลูกเป็ดขี้เหร่ทันที</p><p>ทฤษฎีดังกล่าวชื่อว่าทฤษฎีลูกเป็ดขี้เหร่ เสนอโดย Satosi Watanabe ให้สรุปคร่าวๆ คือเราไม่สามารถ “แปะป้าย” อะไรก็ตามได้เลยหากเราไม่ได้ใส่ “อคติ” ลงไปขณะแปะป้าย เหมือนที่เราไม่สามารถแปะป้ายว่าใครจะเดือดร้อน ถ้าเราไม่ได้ใส่ชุดความคิดของเราว่าคนแบบไหนถึงจะเดือดร้อนเข้าไป–ซึ่งนี่แหละคืออคติ</p><p>และเป็นอคติอันนี้เอง ที่ AI ดูดซับและเรียนรู้เข้าไปอย่างเต็มเปี่ยม เป็นอคติจากมนุษย์ที่สถิตย์เข้าไปใน AI จนดูเหมือนว่าไม่มีมนุษย์คนใดต้องรับผิดชอบจากอคติดังกล่าว<br>แต่ไม่ใช่เลย ไม่เป็นความจริงเลย, ไม่ว่าจะเป็นมนุษย์ที่สร้างอคติ หรือมนุษย์ที่จับอคติลงไปใส่ใน AI ก็ล้วนต้องรับผิดชอบทั้งสิ้น</p><p>อย่าปล่อยให้คำว่า “AI คัดกรอง” เป็นตัวตัดจบบทสนทนา</p><h3>ว่าด้วยอคติจากขั้นตอนวิธี</h3><p>สมมติว่าสุดท้ายเรามีสุดยอดมนุษย์ที่ปราศจากอคติใดๆ ทั้งปวง แปะป้ายข้อมูลประหนึ่งเทพลงมาจุติ ประชากรไทยทั้ง 70 ล้านคนเห็นด้วยว่าคนแบบนี้คือคนที่ควรและไม่ควรได้รับเงินเยียวยาจริงๆ</p><p>ในข้อมูลที่แปะป้าย มีประชากร 3 ใน 10 คนที่ได้รับการเยียวยา ส่วนอีก 7 ใน 10 ไม่ได้รับการเยียวยา ประชากรนั้นประกอบอาชีพแตกต่างกันออกไป ข้อมูลชุดนี้ถูกนำมาฝึกสอน AI คัดแยกว่าใครควรหรือไม่ควรได้รับเงิน ทันใดนั้นเอง…</p><p>พบประชากร 1 คนมีอาชีพอะไรสักอย่าง ดูแล้วควรจะได้เงินกระมัง แต่ว่าอาชีพนี้ไม่ปรากฎอยู่ในข้อมูลที่ถูกแปะป้ายแล้วนำไปสอน กล่าวคือเป็นอาชีพที่ AI ก็เพิ่งมารู้จักตะกี้นี่แหละ</p><p>คำถามคือ หากตัดสินจากอาชีพ ประชากรคนนี้จะได้เงินหรือไม่ได้เงิน</p><figure><img src=\"https://srakrn.me/blog/wp-content/uploads/2020/04/Slide3.png\" alt=\"\" srcset=\"https://srakrn.me/blog/wp-content/uploads/2020/04/Slide3-300x169.png 300w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide3-768x432.png 768w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide3-1024x576.png 1024w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide3-1100x619.png 1100w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide3.png 1280w\" sizes=\"(max-width: 1280px) 100vw, 1280px\"><figcaption>Icons made by <a href=\"https://www.flaticon.com/authors/smalllikeart\">smalllikeart</a> from <a href=\"https://www.flaticon.com/\">www.flaticon.com</a></figcaption></figure><p>คำตอบอาจจะเป็นเรื่องที่น่าเศร้า–แต่ภายใต้วิธีการเรียนรู้หลายๆ วิธี ชายคนนี้จะถูกจัดกลุ่มให้อยู่ในรูปของ “คนส่วนใหญ่” ซึ่งในที่นี้ก็คือคนที่ไม่ได้เงิน ด้วยเหตุผลว่า AI ที่เห็นข้อมูลว่าคนดูไม่ได้รับเงินเยียวยามากกว่าคนได้รับเงินเยียวยา ก็จะมีความโน้มเอียงไปหาการตอบว่า “ไม่ได้รับเงิน” มากกว่าที่จะเลือกตอบว่าได้รับเงินนั่นเอง</p><p>ตัวอย่างของอคตินี้เห็นได้ชัดเป็นอย่างยิ่งในการเรียนรู้ของเบยส์ (Bayesian Learning) ซึ่งเราอาจจะคุ้นเคยกันในวิชาสถิติว่าด้วยความน่าจะเป็นแบบมีเงื่อนไข (conditional probability)</p><figure><img src=\"https://srakrn.me/blog/wp-content/uploads/2020/04/Slide11.png\" alt=\"\" srcset=\"https://srakrn.me/blog/wp-content/uploads/2020/04/Slide11-300x169.png 300w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide11-768x432.png 768w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide11-1024x576.png 1024w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide11-1100x619.png 1100w, https://srakrn.me/blog/wp-content/uploads/2020/04/Slide11.png 1280w\" sizes=\"(max-width: 1280px) 100vw, 1280px\"></figure><p>การเรียนรู้ของเบยส์อยู่บนหลักการของการถามคำถามว่า “ถ้า B แล้วจะ A ไหม” ในที่นี้คือการถามว่า “ถ้าประกอบอาชีพ XYZ แล้วจะได้เงินไหม” ซึ่งการตอบคำถามนี้มีปัจจัยเข้ามาเกี่ยวข้องสามตัวด้วยกัน</p><ul><li>มีคนกี่คนที่ได้เงิน แล้วประกอบอาชีพ XYZ (เอาเฉพาะคนได้เงินมาดู)</li><li>มีคนกี่คนที่ได้เงิน (อัตราส่วนคนได้เงินต่อคนทั้งหมด)</li><li>มีคนกี่คนที่ทำอาชีพ XYZ ต่อคนทั้งหมด</li></ul><p>จะเห็นได้ว่าปัจจัยที่มีปัญหาคือปัจจัยที่สอง เพราะว่าในเมื่อแบบจำลองไม่เคยเห็นอาชีพ XYZ จึงไม่สามารถคิดปัจจัยที่หนึ่งและสามได้ ทำให้ต้องตัดสินใจจากปัจจัยที่สอง–นั่นคือดูว่ามีคนได้เงินเยอะหรือน้อย โดยไม่ได้แม้แต่จะใส่ใจว่าเขาทำอาชีพใด</p><p>ที่จริงแล้วปัญหาดังกล่าวเป็นหนึ่งในปัญหาสำคัญของการทำจักรกลเรียนรู้ (Machine Learning) ที่เรียกว่าปัญหาความไม่สมดุลของชุดข้อมูล (class imbalance) การที่มีข้อมูลที่โน้มเอียงไปยังทางใดทางหนึ่ง (เช่นในตัวอย่างที่โน้มเอียงไปทางไม่แจกเงิน) ย่อมทำให้เกิดการเลือกตอบที่เอียงไปตามข้อมูล แม้ว่ามนุษย์ผู้แปะป้ายจะไม่มีอคติเลยก็ตาม<br></p></div><span>2020-05-17T21:03:21+00:00</span></article></section></main></div><a></a></div>","author":"@srakrn","siteTitle":"@srakrn's Blog","siteHash":"8610f010f52679fdf8125827e361d560c59c9ee46c9232365fabf44f77865fb7","entryHash":"7e6f3a1265a26168b43edf0ade3998ebfa9641288e98f3f7ec2867da7e7a464e","category":"Thai"}