{"title":"419 Automated individual animal identification and feeding bunk scoring: a computer vision approach for beef cattle at Calan gate feeding system","link":"https://academic.oup.com/jas/article/102/Supplement_3/2/7757157?rss=1","date":1726185600000,"content":"<span><div>Abstract</div>Recent developments in computer vision (CV) technology have significantly improved the management of beef cattle feeding systems by enabling precise monitoring and adjustment of feed intake based on individual needs. This study introduces an automated approach for identifying cattle at feeding bunks using CV and evaluates the effectiveness of a feeding bunk scoring system to optimize cattle feeding strategies. Utilizing a high-definition video capture setup, our research focused on the feeding behaviors of 6 heifers in one pen with the Calan Feeding System (American Calan, Northwood, NH). We deployed three Reolink PoE cameras (Model D400) strategically positioned above the feeding bunks, each overseeing two feeding bunks, to monitor feeding activity comprehensively. The cameras were set to record in Full HD (1920 x 1080 pixels) at 30 frames per second. We processed the frames using Python’s OpenCV, resulting in 600 images that composed an array with dimensions 600 x 400x450 (pixels) x 3 (RGB). These images served as the basis for our analysis, which involved feature extraction via a ResNet-50 convolutional neural network, followed by dimensionality reduction through Principal Component Analysis (PCA) and t-distributed Stochastic Neighbor Embedding (t-SNE). Our methodology included the use of k-means clustering to detect the presence of cattle at the bunk, achieving an Adjusted Rand Index (ARI) of 0.9933. We applied the DBSCAN clustering algorithm in the ‘cattle present’ images for individual animal identification, obtaining an ARI of 0.9174, indicating high model accuracy. To assess feeding efficiency, we analyzed 12,156 images of feeding bunks obtained using the same Python’s OpenCV approach and then classified them into six categories based on Lundy et al., 2015: S00 (no feed), S05 (scattered feed), S10 (thin layer), S20 (25 to 50%), S30 (&gt;50%), and S40 (untouched). Using a training, validation, and testing split of 70%, 15%, and 15%, respectively, our model demonstrated exceptional precision, recall, and F1 scores of 0.9989 and predictions in the Confusion Matrix testing accuracy of 99.89%, showcasing the model accuracy. However, when applied to a similar classification using the same Calan gate system, with 7,905 images, the performance of the model decreased, with less precision (0.5868), recall (0.3982), and F1 score (0.3653), most related to classes S10, S20, and S40, underscoring the need for further model refinement. Our findings highlight the potential of integrating CV into precision livestock farming, automating the identification of cattle at feeding bunks, and correlating it with feeding scores to estimate individual consumption accurately. This integration promises to enhance sustainable farming by enabling more precise resource utilization and optimizing individual animal performance. With CV technology, producers can significantly improve production efficiency, health management, and environmental sustainability within their operations. The technology also has a crucial role in reducing operational costs, making it a cost-effective and sustainable production method.</span>","author":"","siteTitle":"Journal of Animal Science Current Issue","siteHash":"e0a9c8db33f44d0a010c49c2ee87259ddd1875917af2bbb2b4ca0cd095c0aaf6","entryHash":"596e6c3738d3c4f4edd84f670e081549da2011d5457509bdced7833a11826132","category":"Environment"}