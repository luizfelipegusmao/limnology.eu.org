{"title":"Mobile Spatiotemporal Gait Segmentation Using an Ear-Worn Motion Sensor and Deep Learning","link":"https://www.preprints.org/manuscript/202408.1616/v1","date":1724299267000,"content":"Mobile health technologies enable continuous, quantitative assessment of mobility and gait in real-world environments, facilitating early diagnosis of gait disorders, disease progression monitoring, and prediction of adverse events like falls. Traditionally, mobile gait assessment predominantly relied on body-fixed sensors positioned at the feet or lower trunk. Here, we investigate the potential of an algorithm utilizing an ear-worn motion sensor for spatiotemporal segmentation of gait patterns. We collected 3D acceleration profiles from the ear-worn sensor during varied walking speeds in 53 healthy adults. Temporal convolutional networks were trained to detect stepping sequences and predict spatial relations between steps. The resulting algorithm, mEar, accurately detects initial and final ground contacts (F1 score of 99% and 91%, respectively). It enables determination of temporal and spatial gait cycle characteristics (among others stride time and stride length) with good to excellent validity at a precision sufficient to monitor clinically relevant changes in walking speed, stride-to-stride variability, and side asymmetry. This study highlights the ear as a viable site for monitoring gait and proposes its potential integration with in-ear vital sign monitoring. Such integration offers a practical approach to comprehensive health monitoring and telemedical applications, by integrating multiple sensors in a single anatomical location.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"578eeb9033fab1402f1efb8f675ee506c763586695132cc323c402c368a88697","category":"Interdisciplinary"}