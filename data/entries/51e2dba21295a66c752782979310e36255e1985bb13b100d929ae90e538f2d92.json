{"title":"Analyzing Multi-Head Attention on Broken BERT Models","link":"https://www.preprints.org/manuscript/202406.1669/v1","date":1719230016000,"content":"This project investigates the behavior of multi-head attention in Transformer models, specifically focusing on the differences between benign and trojan models in the context of sentiment analysis. Trojan attacks cause models to perform normally on clean inputs but exhibit misclassifications when presented with inputs containing predefined triggers. We characterize attention head functions in trojan and benign models, identifying specific 'trojan' heads and analyzing their behavior.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"51e2dba21295a66c752782979310e36255e1985bb13b100d929ae90e538f2d92","category":"Interdisciplinary"}