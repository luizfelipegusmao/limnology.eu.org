{"title":"Performance of ChatGPT on Chinese Master’s Degree Entrance Examination in Clinical Medicine","link":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0301702","date":1712239200000,"content":"<p>by Ke-Cheng Li, Zhi-Jun Bu, Md. Shahjalal, Bai-Xiang He, Zi-Fan Zhuang, Chen Li, Jian-Ping Liu, Bin Wang, Zhao-Lan Liu</p>\r\nBackground <p>ChatGPT is a large language model designed to generate responses based on a contextual understanding of user queries and requests. This study utilised the entrance examination for the Master of Clinical Medicine in Traditional Chinese Medicine to assesses the reliability and practicality of ChatGPT within the domain of medical education.</p> Methods <p>We selected 330 single and multiple-choice questions from the 2021 and 2022 Chinese Master of Clinical Medicine comprehensive examinations, which did not include any images or tables. To ensure the test’s accuracy and authenticity, we preserved the original format of the query and alternative test texts, without any modifications or explanations.</p> Results <p>Both ChatGPT3.5 and GPT-4 attained average scores surpassing the admission threshold. Noteworthy is that ChatGPT achieved the highest score in the Medical Humanities section, boasting a correct rate of 93.75%. However, it is worth noting that ChatGPT3.5 exhibited the lowest accuracy percentage of 37.5% in the Pathology division, while GPT-4 also displayed a relatively lower correctness percentage of 60.23% in the Biochemistry section. An analysis of sub-questions revealed that ChatGPT demonstrates superior performance in handling single-choice questions but performs poorly in multiple-choice questions.</p> Conclusion <p>ChatGPT exhibits a degree of medical knowledge and the capacity to aid in diagnosing and treating diseases. Nevertheless, enhancements are warranted to address its accuracy and reliability limitations. Imperatively, rigorous evaluation and oversight must accompany its utilization, accompanied by proactive measures to surmount prevailing constraints.</p>","author":"Ke-Cheng Li","siteTitle":"PLOS ONE","siteHash":"e9ab556ceb1e4ea76e897a5fa4f394f0bb75c2c2f3d5b0f4766ff77b4a262ac1","entryHash":"8ce665e841124f835da40b665153205d466e607d63c7f2ae22d978a2402f2e7a","category":"Interdisciplinary"}