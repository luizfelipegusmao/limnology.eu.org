{"title":"Enhancing Natural Language to Code Generation in the SantaCoder Model through In-Context Learning","link":"https://www.preprints.org/manuscript/202406.1105/v1","date":1718603828000,"content":"Generating executable code from natural language instructions using Large Language Models (LLMs) presents challenges such as semantic understanding and handling ambiguous input. This study focuses on the SantaCoder model and explores the impact of in-context learning on code generation using the MBPP and HumanEval datasets for evaluation. Our results demonstrate significant improvements in three key metrics (defined in the paper): correctness@k, similarity@k and pass@k. To address the problem of selecting optimal demonstrations to maximize correctness and pass rates, we investigate two methods: latent concept selection and random selection in this paper. These findings highlight the effectiveness of in-context learning and the critical role of demonstration selection in enhancing the accuracy, efficiency, and versatility of the SantaCoder model in code generation.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"14ac6d05ea25f32491dabf88c96a54202cbf02b40b55e1421d1462be108d8711","category":"Interdisciplinary"}