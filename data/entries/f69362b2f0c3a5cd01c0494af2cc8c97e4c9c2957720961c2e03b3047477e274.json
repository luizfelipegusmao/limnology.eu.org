{"title":"AWDP-FL: An Adaptive Differential Privacy Federated Learning Framework","link":"https://www.preprints.org/manuscript/202408.1270/v1","date":1724122748000,"content":"Data security and user privacy concerns are increasingly gaining attention. Federated learning models based on differential privacy offer a distributed machine learning framework that protects data privacy; however, the added noise can impact the model's utility, making performance evaluation crucial. To optimize the balance between privacy protection and model performance, we propose the Adaptive Weight-Based Differential Privacy Federated Learning (AWDP-FL) framework. This framework processes model parameters from the perspectives of neural network layers and model weights. Initially, each participant trains the model locally. During iterative training, the clipping threshold is determined by selecting an adaptive weight coefficient, followed by adaptive gradient clipping to control the gradient magnitude. Subsequently, adaptive gradient updates are applied to the model, and dynamic Gaussian noise is introduced when uploading the parameters to protect participant privacy. The server aggregates these noise-perturbed parameters to update the global model. This framework ensures strong privacy protection while maintaining model accuracy. Theoretical analysis and experimental results validate the effectiveness of this framework under stringent privacy constraints.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"f69362b2f0c3a5cd01c0494af2cc8c97e4c9c2957720961c2e03b3047477e274","category":"Interdisciplinary"}