{"title":"Trackerless 3D Freehand Ultrasound Reconstruction: A Review","link":"https://www.preprints.org/manuscript/202408.1319/v1","date":1724143241000,"content":"Two-dimensional ultrasound (2D US) is commonly used in clinical settings for its cost-effectiveness and non-invasiveness, but it is limited by spatial orientation and operator dependency. Three-dimensional ultrasound (3D US) overcomes these limitations by adding a third dimension and enhancing integration with other imaging modalities. Advances in deep learning (DL) have further propelled the viability of freehand image-based 3D reconstruction, broadening clinical applications in intraoperative and point-of-care (POC) settings. This review evaluates state-of-the-art freehand 3D US reconstruction methods that eliminate the need for external tracking devices, focusing on experimental setups, data acquisition strategies, and reconstruction methodologies. PubMed, Scopus, and IEEE Xplore were searched for studies since 2014 following PRISMA guidelines, excluding those using additional imaging or tracking systems other than inertial measurement units (IMUs). Fourteen eligible studies were analyzed, showing a shift from traditional speckle decorrelation towards DL-based methods, particularly Convolutional Neural Networks (CNNs). Variability in datasets and evaluation methods hindered a comprehensive quantitative comparison, but notable accuracy improvements were observed with IMUs and integration of contextual and temporal information within CNNs. These advancements enhance freehand 3D US reconstruction feasibility, though variability limits definitive conclusions about the most effective methods. Future research should focus on improving precision in complex trajectories and adaptability across clinical scenarios.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"7a6b53b23d9dc1c1fae8785a3eca96d6c001e27038d56c742f92ba178bd9b5d8","category":"Interdisciplinary"}