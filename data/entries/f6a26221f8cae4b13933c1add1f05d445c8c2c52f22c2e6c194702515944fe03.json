{"title":"Addressing Bias and Fairness using Fair Federated Learning: A Systematic Literature Review","link":"https://www.preprints.org/manuscript/202410.1060/v1","date":1728957327000,"content":"In the field of machine learning, the rapid development of data volume and variety requires ethical data utilization and strict privacy protection standards. Fair Federated Learning (FFL) has emerged as a key solution that aims to ensure fairness and privacy protection in a distributed learning environment. FFL enhances privacy protection and solves the inherent limitations of existing federated learning (FL) by promoting fair model training in diverse participant groups, preventing the exclusion of individual users or minorities, and improving overall model fairness. In this study, FFL discusses the causes of bias and fairness of existing FL, and separates solutions based on data partitioning strategies, privacy mechanisms, applicable machine learning models, communication architectures, and technologies to overcome heterogeneity. In order to improve the causes of bias, fairness, and privacy protection of FL, fairness evaluation indicators and applications and challenges of FFL are discussed. Since it addresses bias, fairness, and privacy issues in FL of all mechanisms, it can be an important resource for practitioners who want to implement efficient FL solutions.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"f6a26221f8cae4b13933c1add1f05d445c8c2c52f22c2e6c194702515944fe03","category":"Interdisciplinary"}