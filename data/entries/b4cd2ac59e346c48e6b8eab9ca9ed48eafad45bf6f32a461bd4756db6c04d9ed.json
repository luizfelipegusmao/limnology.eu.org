{"title":"Prediction of Students&#039; Adaptability Using Explainable AI in Educational Machine Learning Models","link":"https://www.preprints.org/manuscript/202405.0933/v1","date":1715673645000,"content":"As the educational landscape evolves, understanding and fostering student adaptability has become increasingly critical. This study presents a comparative analysis of (XAI) techniques to interpret machine learning models aimed at classifying student adaptability levels. Leveraging a robust dataset, we employed several machine learning algorithms with a particular focus on Random Forest, which demonstrated a 91% accuracy. Our study utilizes (SHAP), (LIME), Anchors, (ALE), and counterfactual explanations to reveal the specific contributions of various features impacting adaptability predictions. Consistently, 'Class Duration' and 'Financial Condition' emerge as key factors, while the study also underscores the subtle effects of 'Institution Type' and 'Load-shedding'. This multi-faceted interpretability approach bridges the gap between machine learning performance and educational relevance, presenting a model that not only predicts but also explains the dynamic factors influencing student adaptability. The synthesized insights advocate for educational policies accommodating socioeconomic factors, instructional time, and infrastructure stability to enhance student adaptability. The implications extend to informed and personalized educational interventions, fostering an adaptable learning environment. This methodical research contributes to responsible AI application in education, promoting predictive and interpretable models for equitable and effective educational strategies.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"b4cd2ac59e346c48e6b8eab9ca9ed48eafad45bf6f32a461bd4756db6c04d9ed","category":"Interdisciplinary"}