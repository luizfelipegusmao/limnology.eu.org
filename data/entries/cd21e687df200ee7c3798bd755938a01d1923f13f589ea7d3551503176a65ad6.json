{"title":"Generative AI for Culturally Responsive Assessment in Science: A Conceptual Framework","link":"https://www.preprints.org/manuscript/202409.1276/v2","date":1729503521000,"content":"This study presents a novel approach to automatic generation of cultural and context-specific science assessments for K-12 education using generative AI (GenAI). We first developed a GenAI Culturally Responsive Science Assessment (GenAI-CRSciA) framework that establishes the relationship between CRSciA and GenAI, by incorporating key cultural tenets such as indigenous language, Indigenous knowledge, ethnicity/race, and religion. The CRSciA framework along with dynamic prompt strategies were used to develop the CRSciA-Generator model within the OpenAI platform. The CRSciA-Generator allows users to automatically generate assessments tailored to students’ cultural and contextual needs. In a pilot comparison test between the CRSciA-Generator and the base GPT 4o (with standard prompt), the models were tasked with generating CRSciAs that aligned with the Next Generation Science Standard on predator and prey relationship for students from Ghana, the USA, and China. The results showed that the CRSciA-Generator output assessments incorporated more tailored culturally and context assessment items for each specific group with examples, such as traditional stories of lions and antelopes in Ghana, Native American views on wolves in the USA, and Taoist or Buddhist teachings on the Amur tiger in China than the standard prompt out within the base GPT 4o. However, due to the background information provided, the CRSciA-Generator overgeneralized its output focusing on broad national contexts, treating entire countries as culturally homogenous and neglecting the subcultures. Therefore, we recommend that teachers provide detailed background information about their students when using the CRSciA-Generator. Additionally, we believe the pilot test did not fully validate the model’s efficacy, and future studies involving human experts’ review are recommended to evaluate the cultural and contextual validity of the generated assessments. We also suggest empirical studies in diverse contexts to further test and validate the model’s overall effectiveness.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"cd21e687df200ee7c3798bd755938a01d1923f13f589ea7d3551503176a65ad6","category":"Interdisciplinary"}