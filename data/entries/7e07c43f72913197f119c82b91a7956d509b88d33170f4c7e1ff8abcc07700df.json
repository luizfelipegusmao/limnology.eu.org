{"title":"Fair Federated Learning","link":"https://www.preprints.org/manuscript/202409.0544/v1","date":1725618525000,"content":"Optimization is critical in various fields like smart vehicles, and transportation. Federated Learning (FL) has emerged as an effective approach in the coordination of autonomous vehicles, but traditional methods such as FedAvg can create performance disparities across clients. This paper addresses this fairness issue through the $q$-Fair Federated Learning ($q$-FFL) framework, adjusting model performance across clients using a tunable fairness parameter. We propose a modified FedAvg algorithm for $q$-FFL that maintains comparable convergence rates, ensuring more balanced client outcomes. Additionally, we explore incentive mechanisms in FL using a Stackelberg game model, incorporating a fairness coefficient to encourage equitable participation. Building on prior works, we redefine client utility functions to address communication and computation costs, ensuring fair resource allocation. The proposed framework achieves both global and local fairness, maintaining a unique Nash equilibrium in the modified game setting.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"7e07c43f72913197f119c82b91a7956d509b88d33170f4c7e1ff8abcc07700df","category":"Interdisciplinary"}