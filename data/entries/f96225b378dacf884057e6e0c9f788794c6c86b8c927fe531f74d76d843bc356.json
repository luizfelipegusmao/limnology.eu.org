{"title":"Automating field‐based floral surveys with machine learning","link":"https://besjournals.onlinelibrary.wiley.com/doi/10.1002/2688-8319.12393?af=R","date":1728873304000,"content":"<img src=\"https://besjournals.onlinelibrary.wiley.com/cms/asset/def7a156-e8d8-4b0f-9fcb-9995fe705a0e/eso312393-toc-0001-m.png\" alt=\"Automating field-based floral surveys with machine learning\" />\n<p>The abundance and diversity of flowering plant species are important indicators of pollinator habitat quality but require intensive field sampling to measure. In this study, the mapping of floral resources within aerial photography from a consumer-grade drone was automated with a convolutional neural network algorithm. The automated floral abundance counting yielded estimates that were strongly correlated with field-based manual counting and thus provided valuable insights into automated flower classification and abundance estimation using drone imagery and machine learning.</p>\n<br />\n<h2>Abstract</h2>\n<p>\n\nThe abundance and diversity of flowering plant species are important indicators of pollinator habitat quality, but traditional field-based surveying techniques are time-intensive. Therefore, they are often biased due to under-sampling and are difficult to scale.\n\nAerial photography was collected across 10 sites located in and around Rouge National Urban Park, Toronto, Canada using a consumer-grade drone. A convolutional neural network (CNN) was trained to semantically segment, or identify and categorize, pixel clusters which represent flowers in the collected aerial imagery. Specifically, flowers of the dominant taxa found in the depauperate fall flowering plant community were surveyed. This included yellow flowering <i>Solidago</i> spp., white <i>Symphyotrichum ericoides/lanceolatum</i> and purple <i>Symphyotrichum novae-angliae</i>. The CNN was trained using 930 m<sup>2</sup> of manually annotated data, ~1% of the mapped landscape. The trained CNN was tested on 20% of the manually annotated data concealed during training. In addition, it was externally validated by comparing the predicted drone-derived floral abundance metrics (i.e. floral area (m<sup>2</sup>) and the number of floral patches) to the field-based count of floral units estimated for 34 4 m<sup>2</sup> plots.\n\nThe CNN returned accurate multiclassification when evaluated against the testing data. It obtained a precision score of 0.769, a recall of 0.849, and an F1 score of 0.807. The automated floral abundance counting yielded estimates that were strongly correlated with field-based manual counting. In addition, flower segmentation using the trained CNN was time-efficient. On average, it took roughly the same amount of time to segment the flowers occurring in an entire drone scene as it took to complete the abundance count of a single quadrat. However, the training process, particularly manual data annotation, was the most time-consuming component of the study.\n\n<i>Practical implication</i>: Overall, the analysis provided valuable insights into automated flower classification and abundance estimation using drone imagery and machine learning. The results demonstrate that these tools can be used to provide accurate and scalable estimates of pollinator habitat quality. Further research should consider diverse wildflower systems to develop the generalizability of the methods.\n</p>","author":"Nicholas Sookhan, \nShane Sookhan, \nDevlin Grewal, \nJ. Scott MacIvor","siteTitle":"Wiley: Ecological Solutions and Evidence: Table of Contents","siteHash":"2d59a3492421ff8dc6c930252c6b4149e9691eaa8596381f5a50d8e1d8243fb4","entryHash":"f96225b378dacf884057e6e0c9f788794c6c86b8c927fe531f74d76d843bc356","category":"Environment"}