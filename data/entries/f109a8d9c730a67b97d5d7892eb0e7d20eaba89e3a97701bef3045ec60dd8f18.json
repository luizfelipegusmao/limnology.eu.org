{"title":"CS-Evalâ€”A Concise Benchmark for Evaluating the Security Risks of Large Language Models","link":"https://www.preprints.org/manuscript/202409.1098/v1","date":1726235179000,"content":"Large language models (LLMs) are essential to the field of natural language processing, and as their applications expand, security risks have become increasingly prominent. This paper introduces a novel benchmark for evaluating LLMs security, termed CS-Eval, designed to effectively assess the models' ability to address vulnerabilities. CS-Eval targets seven key security risks: ethical dilemmas, marginal topics, error detection, detailed event handling, cognitive bias, logical reasoning, and privacy identification, and establishes a Multi-Security Hazard Dataset (MSHD). The evaluated models include GPT-4o, Llama-3-70B, Claude-3-Opus, ERNIE-4.0, Abab-6.5, Qwen1.5-110B, Gemini-1.5-Pro, Doubao-Pro, SenseChat-V5, and GLM-4. We analyzed each model's performance in relation to these security risks and provided recommendations for improvement. Experimental results demonstrate varying levels of effectiveness across models, with GPT-4o exhibiting the best overall performance. Moreover, the relationship between security enhancement and model capa-bility is nonlinear, indicating that improving safety requires a multifaceted approach, considering various factors in both development and application.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"f109a8d9c730a67b97d5d7892eb0e7d20eaba89e3a97701bef3045ec60dd8f18","category":"Interdisciplinary"}