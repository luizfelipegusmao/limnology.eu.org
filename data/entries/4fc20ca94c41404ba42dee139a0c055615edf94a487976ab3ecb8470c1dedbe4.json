{"title":"Research on SLAM Localization Algorithm for Orchard Dynamic Vision Based on YOLOD-SLAM2","link":"https://www.preprints.org/manuscript/202408.0469/v1","date":1722983369000,"content":"With the development of agriculture, the complexity and dynamism of orchard environments pose challenges to the perception and positioning of inter row environments for agricultural machinery. The paper proposes a method for extracting navigation lines and measuring pedestrian obstacles. The improved YOLOv5 algorithm is used to detect tree trunks between left and right rows in orchards. The experimental results show that the average angle deviation of the extracted navigation lines is less than 5 degrees, verifying its accuracy. Due to the variable posture of pedestrians and ineffective camera depth, a distance measurement algorithm based on four zone depth comparison is proposed for pedestrian obstacle distance measurement. Experimental results show that within a range of 6m, the average relative error of distance measurement does not exceed 1%, and within a range of 9m, the maximum relative error is 2.03%. The average distance measurement time is 30 milliseconds, which can accurately and quickly achieve pedestrian distance measurement in orchard environments. On the publicly available TUM RGB-D dynamic dataset, YOLOD-SLAM2 significantly reduces the RMSE index of absolute trajectory error compared to ORB-SLAM2 algorithm, which is less than 0.05 m/s. In actual orchard environments, YOLOD-SLAM2 has a higher degree of agreement between the estimated trajectory and the true trajectory when the car is traveling in straight and circular directions. The RMSE index of the absolute trajectory error is less than 0.03m/s, and the average tracking time is 47ms, indicating that the YOLOD-SLAM2 algorithm proposed in this paper can meet the accuracy and real-time requirements of agricultural machinery positioning in orchard environments.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"4fc20ca94c41404ba42dee139a0c055615edf94a487976ab3ecb8470c1dedbe4","category":"Interdisciplinary"}