{"title":"Automatic exudate and aneurysm segmentation in OCT images using UNET++ and hyperreflective-foci feature based bagged tree ensemble","link":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0304146","date":1716559200000,"content":"<p>by Rinrada Tanthanathewin, Warissaporn Wongrattanapipat, Tin Tin Khaing, Pakinee Aimmanee</p>\r\n\r\nDiabetic retinopathyâ€™s signs, such as exudates (EXs) and aneurysms (ANs), initially develop from under the retinal surface detectable from optical coherence tomography (OCT) images. Detecting these signs helps ophthalmologists diagnose DR sooner. Detecting and segmenting exudates (EXs) and aneurysms (ANs) in medical images is challenging due to their small size, similarity to other hyperreflective regions, noise presence, and low background contrast. Furthermore, the scarcity of public OCT images featuring these abnormalities has limited the number of studies related to the automatic segmentation of EXs and ANs, and the reported performance of such studies has not been satisfactory. This work proposes an efficient algorithm that can automatically segment these anomalies by improving key steps in the process. The potential area where these hyper-reflective EXs and ANs occur was scoped by our method using a deep-learning U-Net++ program. From this area, the candidates for EX-AN were segmented using the adaptive thresholding method. Nine features based on appearances, locations, and shadow markers were extracted from these candidates. They were trained and tested using bagged tree ensemble classifiers to obtain only EX-AN blobs. The proposed method was tested on a collection of a public dataset comprising 80 images with hand-drawn ground truths. The experimental results showed that our method could segment EX-AN blobs with average recall, precision, and F1-measure as 87.9%, 86.1%, and 87.0%, respectively. Its F1-measure drastically outperformed two comparative methods, binary thresholding and watershed (BT-WS) and adaptive thresholding with shadow tracking (AT-ST), by 78.0% and 82.1%, respectively.","author":"Rinrada Tanthanathewin","siteTitle":"PLOS ONE","siteHash":"e9ab556ceb1e4ea76e897a5fa4f394f0bb75c2c2f3d5b0f4766ff77b4a262ac1","entryHash":"ce3609b5c0dc1412c5639e2aaf316d8a5c167a9d3486b802c89d2426d1f2469a","category":"Interdisciplinary"}