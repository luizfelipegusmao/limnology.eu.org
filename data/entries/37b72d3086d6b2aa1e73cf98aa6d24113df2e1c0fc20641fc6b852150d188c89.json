{"title":"Generative AI Enables Label-Free Segmentation for Live Analysis of Supported Nanoparticle Catalysts","link":"https://academic.oup.com/mam/article/doi/10.1093/mam/ozae044.211/7719950?rss=1","date":1721779200000,"content":"<span>The rapid development of Artificial Intelligence (AI) has facilitated the automated processing of large data stacks for Scanning Transmission Electron Microscopy (STEM). More specifically, computer vision based on deep learning models has been widely used in various applications such as defect detection [<a href=\"#ozae044.211-B1\">1</a>], nanoparticle identification [<a href=\"#ozae044.211-B2\">2</a>], and crystal structure classification [<a href=\"#ozae044.211-B3\">3</a>]. However, a significant challenge remains in the acquisition and labeling of the datasets used to train such deep models. Generally, for the differences in STEM images due to changes in materials or experimental conditions, a new model needs to be trained. Training such a well-performing model requires a large amount of high-quality data with ground truth in pairs for the sake of supervision. However, due to the preciousness of experimental STEM data, most of the time we cannot obtain enough images to fulfill the training requirements. At the same time, manual labeling is a tedious process with human bias, which means the current STEM has not yet reached the level of fully automated analysis. The typical approach is to train with simulated data, which can generate both images and ground truth simultaneously [<a href=\"#ozae044.211-B2\">2</a>]. However, simulated STEM images do not reflect the diversity of real data well, and simulation is also very time-consuming. Therefore, when the model trained with simulated data is confronted with images of different contrasts and resolutions, it may need to be retrained. Here, we turn our attention to generative AI, which can randomly generate highly realistic images, and at the same time, through the rational design of the workflow, it can simultaneously generate paired ground truth. Recently, Huang et al. reported that a cycle generative adversarial network can be used to create realistic STEM images based on simulated images [<a href=\"#ozae044.211-B4\">4</a>]. This method was successfully verified on a recognition network of atomic-level defects. However, it still requires simulation, which is a significant barrier to the generalization of the model. So, we need to find a method to generate training data without simulation and manual labeling, which will be crucial for the development of high-throughput processing of STEM data. Here we demonstrate EMcopilot, a generative AI capable of generating both STEM images and ground truth in pairs, and moreover a co-pilot that provides real-time feedback during STEM operations.</span>","author":"","siteTitle":"Microscopy and Microanalysis Current Issue","siteHash":"4696c64d0a05ab8306669645a687c52cc4f52f5a57db1c180736d38256b41e79","entryHash":"37b72d3086d6b2aa1e73cf98aa6d24113df2e1c0fc20641fc6b852150d188c89","category":"Environment"}