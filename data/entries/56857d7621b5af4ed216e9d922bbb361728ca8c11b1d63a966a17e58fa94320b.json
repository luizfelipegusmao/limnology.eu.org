{"title":"PEAR: A Knowledge-guided Autonomous Pipeline for Ptychography Enabled by Large Language Models","link":"https://academic.oup.com/mam/article/doi/10.1093/mam/ozae044.184/7719523?rss=1","date":1721779200000,"content":"<span>The rapid advancement of artificial intelligence (AI) has catalyzed significant progress in autonomous experimentation and data analysis within the field of microscopy. Recently, large language models (LLMs) have attracted great research interests due to the popularity of OpenAI’s ChatGPT platform [<a href=\"#ozae044.184-B1\">1</a>]. LLMs, which are neural network models trained on extensive datasets, demonstrate “intelligent” capabilities including comprehensive knowledge, common sense, and basic logics [<a href=\"#ozae044.184-B2\">2</a>]. They can be easily adapted to many natural language processing tasks such as search, summarization, reasoning, and planning. Recent breakthroughs have further expanded their utility by enabling the integration of specialized knowledge, tools, and additional modalities (e.g., images). These attributes are particularly beneficial for computational imaging techniques such as ptychography, where the quality of images is heavily influenced by the selection of experimental and reconstruction parameters. Previous works have utilized Bayesian optimization with Gaussian processes to facilitate automatic parameter tuning and experimental designs [<a href=\"#ozae044.184-B3\">3</a>,<a href=\"#ozae044.184-B4\">4</a>]. However, the approach can be less efficient in more routine tasks for experienced researchers whose existing knowledge can guide them obtaining useful results within a few reconstructions.</span>","author":"","siteTitle":"Microscopy and Microanalysis Current Issue","siteHash":"4696c64d0a05ab8306669645a687c52cc4f52f5a57db1c180736d38256b41e79","entryHash":"56857d7621b5af4ed216e9d922bbb361728ca8c11b1d63a966a17e58fa94320b","category":"Environment"}