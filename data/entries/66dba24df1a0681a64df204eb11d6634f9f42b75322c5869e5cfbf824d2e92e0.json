{"title":"From unimodal to multimodal dynamics of verbal and nonverbal cues during unstructured conversation","link":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0309831","date":1727272800000,"content":"<p>by Tifenn Fauviaux, Ludovic Marin, Mathilde Parisi, Richard Schmidt, Ghil√®s Mostafaoui</p>\r\n\r\nConversations encompass continuous exchanges of verbal and nonverbal information. Previous research has demonstrated that gestures dynamically entrain each other and that speakers tend to align their vocal properties. While gesture and speech are known to synchronize at the intrapersonal level, few studies have investigated the multimodal dynamics of gesture/speech between individuals. The present study aims to extend our comprehension of unimodal dynamics of speech and gesture to multimodal speech/gesture dynamics. We used an online dataset of 14 dyads engaged in unstructured conversation. Speech and gesture synchronization was measured with cross-wavelets at different timescales. Results supported previous research on intrapersonal speech/gesture coordination, finding synchronization at all timescales of the conversation. Extending the literature, we also found interpersonal synchronization between speech and gesture. Given that the unimodal and multimodal synchronization occurred at similar timescales, we suggest that synchronization likely depends on the vocal channel, particularly on the turn-taking dynamics of the conversation.","author":"Tifenn Fauviaux","siteTitle":"PLOS ONE","siteHash":"e9ab556ceb1e4ea76e897a5fa4f394f0bb75c2c2f3d5b0f4766ff77b4a262ac1","entryHash":"66dba24df1a0681a64df204eb11d6634f9f42b75322c5869e5cfbf824d2e92e0","category":"Interdisciplinary"}