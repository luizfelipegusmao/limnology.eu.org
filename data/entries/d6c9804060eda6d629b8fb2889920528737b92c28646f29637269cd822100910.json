{"title":"Decoding by Factual Prompts and Hallucination Prompts Improves Factuality in Large Language Models","link":"https://www.preprints.org/manuscript/202409.2037/v1","date":1727334492000,"content":"Although large language models demonstrate impressive capabilities, they sometimes generate irrelevant or nonsensical text, or produce outputs that deviate from the provided source inputâ€”an occurrence commonly referred to as hallucination. To mitigate this issue, we introduce a novel decoding method that incorporates both factual and hallucination prompts(DFHP), utilizing a contrastive output distribution to highlight the disparity in output probabilities between model predictions influenced by factual prompts and those affected by hallucination prompts. Experiments on both multiple-choice and text generation tasks show that our approach significantly enhances the factual accuracy of large language models without requiring additional training.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"d6c9804060eda6d629b8fb2889920528737b92c28646f29637269cd822100910","category":"Interdisciplinary"}