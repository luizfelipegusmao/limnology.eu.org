{"title":"Attention to audiovisual speech shapes neural processing through feedback-feedforward loops between different nodes of the speech network","link":"https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002534","date":1710165600000,"content":"<p>by Patrik Wikman, Viljami Salmela, Eetu Sj√∂blom, Miika Leminen, Matti Laine, Kimmo Alho</p>\r\n\r\nSelective attention-related top-down modulation plays a significant role in separating relevant speech from irrelevant background speech when vocal attributes separating concurrent speakers are small and continuously evolving. Electrophysiological studies have shown that such top-down modulation enhances neural tracking of attended speech. Yet, the specific cortical regions involved remain unclear due to the limited spatial resolution of most electrophysiological techniques. To overcome such limitations, we collected both electroencephalography (EEG) (high temporal resolution) and functional magnetic resonance imaging (fMRI) (high spatial resolution), while human participants selectively attended to speakers in audiovisual scenes containing overlapping cocktail party speech. To utilise the advantages of the respective techniques, we analysed neural tracking of speech using the EEG data and performed representational dissimilarity-based EEG-fMRI fusion. We observed that attention enhanced neural tracking and modulated EEG correlates throughout the latencies studied. Further, attention-related enhancement of neural tracking fluctuated in predictable temporal profiles. We discuss how such temporal dynamics could arise from a combination of interactions between attention and prediction as well as plastic properties of the auditory cortex. EEG-fMRI fusion revealed attention-related iterative feedforward-feedback loops between hierarchically organised nodes of the ventral auditory object related processing stream. Our findings support models where attention facilitates dynamic neural changes in the auditory cortex, ultimately aiding discrimination of relevant sounds from irrelevant ones while conserving neural resources.","author":"Patrik Wikman","siteTitle":"PLOS Biology","siteHash":"63268de9c1fab91327fb48afeeb83afb4047c365a2f6807080f2b99ab35eb8c8","entryHash":"b429aec348d7cd372de7b9653b22c26404f577aea6b01f3b74967db98454022e","category":"Environment"}