{"title":"Raman spectroscopic deep learning with signal aggregated representations for enhanced cell phenotype and signature identification","link":"https://academic.oup.com/pnasnexus/article/doi/10.1093/pnasnexus/pgae268/7704537?rss=1","date":1719964800000,"content":"<span><div>Abstract</div>Feature representation is critical for data learning, particularly in learning spectroscopic data. Machine learning (ML) and deep learning (DL) models learn Raman spectra for rapid, nondestructive, and label-free cell phenotype identification, which facilitate diagnostic, therapeutic, forensic, and microbiological applications. But these are challenged by high-dimensional, unordered, and low-sample spectroscopic data. Here, we introduced novel 2D image-like dual signal and component aggregated representations by restructuring Raman spectra and principal components, which enables spectroscopic DL for enhanced cell phenotype and signature identification. New ConvNet models DSCARNets significantly outperformed the state-of-the-art (SOTA) ML and DL models on six benchmark datasets, mostly with &gt;2% improvement over the SOTA performance of 85â€“97% accuracies. DSCARNets also performed well on four additional datasets against SOTA models of extremely high performances (&gt;98%) and two datasets without a published supervised phenotype classification model. Explainable DSCARNets identified Raman signatures consistent with experimental indications.</span>","author":"","siteTitle":"PNAS Nexus Current Issue","siteHash":"fea58439d6cc2c0ccad3ee11497de51870b6a2407c2235f665cca3245ef20ac2","entryHash":"5baf9b0981a36d2692c4f8a65779e4f2fcac0b012259290de37192e3b790ecc8","category":"Interdisciplinary"}