{"title":"Distilling Knowledge from Multiple Foundation Models for Zero-shot Image classification","link":"https://www.preprints.org/manuscript/202406.1153/v1","date":1718619118000,"content":"This paper introduces a novel framework for zero-shot learning (ZSL), i.e., to recognize new categories that are unseen during training, by distilling knowledge from foundation models. Specifically, we first employ ChatGPT and DALL-E to synthesize reference images of unseen categories from text prompts. Then, the test image is aligned with text and reference images using CLIP and DINO. Finally, the predicted logits are aggregated according to their confidence to produce the final prediction.Experiments are conducted on multiple datasets, including CIFAR-10, CIFAR-100, and TinyImageNet. The results demonstrate that our model can significantly improve classification accuracy compared to previous approaches, achieving AUROC scores above 96\\% across all test datasets. Our code is available at https://github.com/1134112149/MICW-ZIC.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"eb7f3fc7b01605a4494a0281b5f7e42dcfb2f3864469f6a76e8e14ba2e603248","category":"Interdisciplinary"}