{"title":"Extended Reality and Multimodal Artificial Intelligence for Human Performance: A Review of Current Status and Future Outlook","link":"https://www.preprints.org/manuscript/202410.1023/v1","date":1728985745000,"content":"Advanced technologies have had a transformative impact on education. In this paper, we explored the current status and future outlook of the use of AI-supported multimodal extended reality for human performance. Using a systematic scoping review design and a machine learning-based semi-automatic approach supplemented by pattern review, we derived several insights into AI-supported multimodal extended reality for human performance. Text mining and topic modeling revealed an optimal twenty-six topics from the included studies. These classifications are salient in the extended reality technologies used (i.e., virtual and augmented reality), the multimodal techniques involved (i.e., haptic, eye, and brain tracking), and the AI leveraged (i.e., machine learning accuracy). Through pattern review, we distilled topical patterns on 1) Goals and Outcomes of AI-supported Multimodal Extended Reality for Human Performance; 2) Disentangling the Dynamics of User Interactions in Virtual Environments with Multimodal Strategies; 3) Synergistic Multimodality with Emerging AI Technologies Using Machine Learning, LLMs, and VLMs; 4) Fostering Engaging, Interactive and Immersive Human Experiences through Ambient Intelligence. These nuanced details in AI-supported multimodal extended reality are emerging, yet not established enough to be classified through text mining and topic modeling. We discussed the implications of these findings for AI-supported multimodal extended reality for human performance in future research and practice.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"a00a6eae597d49375cce032b2c6de63a408d90879943ab344e67620ec9963cb1","category":"Interdisciplinary"}