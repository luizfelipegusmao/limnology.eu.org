{"title":"Distilling knowledge from multiple foundation models for zero-shot image classification","link":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0310730","date":1726840800000,"content":"<p>by Siqi Yin, Lifan Jiang</p>\r\n\r\nZero-shot image classification enables the recognition of new categories without requiring additional training data, thereby enhancing the modelâ€™s generalization capability when specific training are unavailable. This paper introduces a zero-shot image classification framework to recognize new categories that are unseen during training by distilling knowledge from foundation models. Specifically, we first employ ChatGPT and DALL-E to synthesize reference images of unseen categories from text prompts. Then, the test image is aligned with text and reference images using CLIP and DINO to calculate the logits. Finally, the predicted logits are aggregated according to their confidence to produce the final prediction. Experiments are conducted on multiple datasets, including MNIST, SVHN, CIFAR-10, CIFAR-100, and TinyImageNet. The results demonstrate that our method can significantly improve classification accuracy compared to previous approaches, achieving AUROC scores of over 96% across all test datasets. Our code is available at https://github.com/1134112149/MICW-ZIC.","author":"Siqi Yin","siteTitle":"PLOS ONE","siteHash":"e9ab556ceb1e4ea76e897a5fa4f394f0bb75c2c2f3d5b0f4766ff77b4a262ac1","entryHash":"01dd41bf852de653ec49c50c41a08690e4a1edff6d9bc2fcdaee45889a40fe51","category":"Interdisciplinary"}