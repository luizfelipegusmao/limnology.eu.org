{"title":"Evaluating the competency of ChatGPT in MRCP Part 1 and a systematic literature review of its capabilities in postgraduate medical assessments","link":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0307372","date":1722434400000,"content":"<p>by Oliver Vij, Henry Calver, Nikki Myall, Mrinalini Dey, Koushan Kouranloo</p>\r\nObjectives <p>As a large language model (LLM) trained on a large data set, ChatGPT can perform a wide array of tasks without additional training. We evaluated the performance of ChatGPT on postgraduate UK medical examinations through a systematic literature review of ChatGPTâ€™s performance in UK postgraduate medical assessments and its performance on Member of Royal College of Physicians (MRCP) Part 1 examination.</p> Methods <p>Medline, Embase and Cochrane databases were searched. Articles discussing the performance of ChatGPT in UK postgraduate medical examinations were included in the systematic review. Information was extracted on exam performance including percentage scores and pass/fail rates.MRCP UK Part 1 sample paper questions were inserted into ChatGPT-3.5 and -4 four times each and the scores marked against the correct answers provided.</p> Results <p>12 studies were ultimately included in the systematic literature review.ChatGPT-3.5 scored 66.4% and ChatGPT-4 scored 84.8% on MRCP Part 1 sample paper, which is 4.4% and 22.8% above the historical pass mark respectively. Both ChatGPT-3.5 and -4 performance was significantly above the historical pass mark for MRCP Part 1, indicating they would likely pass this examination.ChatGPT-3.5 failed eight out of nine postgraduate exams it performed with an average percentage of 5.0% below the pass mark.ChatGPT-4 passed nine out of eleven postgraduate exams it performed with an average percentage of 13.56% above the pass mark. ChatGPT-4 performance was significantly better than ChatGPT-3.5 in all examinations that both models were tested on.</p> Conclusion <p>ChatGPT-4 performed at above passing level for the majority of UK postgraduate medical examinations it was tested on. ChatGPT is prone to hallucinations, fabrications and reduced explanation accuracy which could limit its potential as a learning tool. The potential for these errors is an inherent part of LLMs and may always be a limitation for medical applications of ChatGPT.</p>","author":"Oliver Vij","siteTitle":"PLOS ONE","siteHash":"e9ab556ceb1e4ea76e897a5fa4f394f0bb75c2c2f3d5b0f4766ff77b4a262ac1","entryHash":"cc374b0c63a27906bf4846123643f873c11ac644d551638462e216882c14374f","category":"Interdisciplinary"}