{"title":"Detecting flowers on imagery with computer vision to improve continental scale grassland biodiversity surveying","link":"https://besjournals.onlinelibrary.wiley.com/doi/10.1002/2688-8319.12324?af=R","date":1716447600000,"content":"<img src=\"https://besjournals.onlinelibrary.wiley.com/cms/asset/a5459554-ddc6-45e6-9553-08f8628e63e1/eso312324-toc-0001-m.png\" alt=\"Detecting flowers on imagery with computer vision to improve continental scale grassland biodiversity surveying\" />\n<p>Large scale biodiversity monitoring is essential for assessing biodiversity trends, yet traditional surveying methods are limited in the spatial/temporal scale they can cover. We trained a model with a dataset using 500 manually delineated images of vegetation patches in European grasslands which was able to automatically extract valuable information on floral abundances, colours and sizes.</p>\n<br />\n<h2>Abstract</h2>\n<p>\n\nLarge-scale biodiversity monitoring is essential for assessing biodiversity trends, yet traditional surveying methods are limited in the spatial/temporal scale they can cover. Recent technological developments have led to computer vision-based species identification tools, such as the Pl@ntNet application. Increasing accuracy of such algorithms presents an opportunity of integrating computer vision into larger monitoring schemes and could lead to automating ground-based evidence provision related to agri-environmental measures (e.g. flower strips, field margins). However, images from surveys or farmer declarations do not live up to the standards of current applications. In order to integrate these automated methods into biodiversity monitoring, more generalized models are needed.\n\nWe create a dataset using 500 manually delineated images of vegetation patches in European grasslands taken during the Land Use/cover Area Survey (LUCAS) grassland module. We train the Faster R-CNN model to detect and extract individual flower objects. Using this model, we extract the abundance of flowers in an image, analyse their colour distribution, and use the Pl@ntNet application to identify the species of the individual flowers detected.\n\nThe best model reaches precision and recall of 0.89/0.61 and predicts 1377 flowers on the 100 test images distributed between 10 colours. Using Pl@ntNet, only 52 flowers were identified with a certainty score above 0.5 due to the limitations in image size and quality. Of these flowers, 30% were correctly automatically identified at the species level and 42% at the genus level.\n\nThe results show that we can automatically extract valuable information on floral abundances, colours, and sizes from images of vegetation patches, though in most cases better images are needed for species identification. Despite limitations with image quality, integrating this workflow into large-scale monitoring could speed up the sampling process and allow for better spatial and temporal data on floral diversity and abundance.\n</p>","author":"N. Elvekjaer, \nL. Martinez‚ÄêSanchez, \nP. Bonnet, \nA. Joly, \nM. L. Paracchini, \nM. van der Velde","siteTitle":"Wiley: Ecological Solutions and Evidence: Table of Contents","siteHash":"2d59a3492421ff8dc6c930252c6b4149e9691eaa8596381f5a50d8e1d8243fb4","entryHash":"1fe856967f9a56c8bc1ab56613b64ab17f7be0756090065726830fa715820358","category":"Environment"}