{"title":"ChatGPT-generated help produces learning gains equivalent to human tutor-authored help on mathematics skills","link":"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0304013","date":1716559200000,"content":"<p>by Zachary A. Pardos, Shreya Bhandari</p>\r\n\r\nAuthoring of help content within educational technologies is labor intensive, requiring many iterations of content creation, refining, and proofreading. In this paper, we conduct an efficacy evaluation of ChatGPT-generated help using a 3 x 4 study design (N = 274) to compare the learning gains of ChatGPT to human tutor-authored help across four mathematics problem subject areas. Participants are randomly assigned to one of three hint conditions (control, human tutor, or ChatGPT) paired with one of four randomly assigned subject areas (Elementary Algebra, Intermediate Algebra, College Algebra, or Statistics). We find that only the ChatGPT condition produces statistically significant learning gains compared to a no-help control, with no statistically significant differences in gains or time-on-task observed between learners receiving ChatGPT vs human tutor help. Notably, ChatGPT-generated help failed quality checks on 32% of problems. This was, however, reducible to nearly 0% for algebra problems and 13% for statistics problems after applying self-consistency, a “hallucination” mitigation technique for Large Language Models.","author":"Zachary A. Pardos","siteTitle":"PLOS ONE","siteHash":"e9ab556ceb1e4ea76e897a5fa4f394f0bb75c2c2f3d5b0f4766ff77b4a262ac1","entryHash":"8aaf5557f26b45ee32533d8ed72b01e6bec54a770371c7a27ef4598186ae02f5","category":"Interdisciplinary"}