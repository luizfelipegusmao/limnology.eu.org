{"title":"Reducing Racial and Ethnic Bias in AI Models: A Comparative Analysis of ChatGPT and Google Bard","link":"https://www.preprints.org/manuscript/202406.2016/v1","date":1719550266000,"content":"53% of adults in the US acknowledge racial bias as a significant issue, 23% of Asian adults experience cultural and ethnic bias, and more than 60% conceal their cultural heritage after racial abuse. AI models like ChatGPT and Google Bard, trained on historically biased data, inadvertently amplify racial and ethnic bias and stereotypes. This paper addresses the issue of racial bias in AI models using scientific, evidence-based analysis and auditing processes to identify biased responses from AI models and develop a mitigation tool. The methodology involves creating a comprehensive database of racially biased questions, terms, and phrases from thousands of legal cases, Wikipedia, and surveys, and then testing them on AI Models and analyzing the responses through sentiment analysis and human evaluation, and eventually creation of an 'AI-BiasAudit,' tool having a racial-ethnic database for social science researchers and AI developers to identify and prevent racial bias in AI models.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"8d245b53a828ace180ee5c60b27022e542cede5d83d1ecfc6e5db8da62ac94aa","category":"Interdisciplinary"}