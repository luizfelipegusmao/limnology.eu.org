{"title":"Co-CrackSegment: A New Corporative Deep Learning Framework for Pixel-Level Semantic Segmentation of Concrete Cracks","link":"https://www.preprints.org/manuscript/202408.1801/v1","date":1724725951000,"content":"In the era of massive construction, damaged and aging infrastructure are becoming more common. Defects, such as cracking, spalling, etc., are main types of structural damage that widely occur. Hence, ensuring the safe operation existing infrastructure through health monitoring has emerged as an important challenge facing structural engineers. In recent years, intelligent approaches, such as data driven machine and deep learning crack detection, gradually dominate over traditional methods. Among them, the semantic segmentation using deep learning models is a process of characterization of accurate location and portrait of cracks using pixel level classification. Most available studies rely on single model knowledge to perform this task. However, it is well-known that the single model might suffer from low variance and low ability to generalize in case of data alteration. By leveraging the ensemble deep learning philosophy, a novel corporative semantic segmentation of concrete cracks method called Co-CrackSegment is proposed. Firstly, five models, namely the U-net, SegNet, DeepCrack19, DeepLabV3-ResNet50, and DeepLabV3-ResNet101 are trained to serve as core models for the ensemble model Co-CrackSegment. To build the ensemble model Co-CrackSegment, a new iterative approach based on the best evaluation metrics, namely the dice score, IoU, pixel accuracy, precision, and recall metrics is developed. Results show that the Co-CrackSegment exhibits a prominent performance compared to core models and weighted average ensemble by means of the considered best statistical metrics.","author":"","siteTitle":"Preprints.org - The Multidisciplinary Preprint Platform","siteHash":"abac34b0506002eba4392ac15186820b9b5d7a0f2e5fce3a3511408258fb1a7e","entryHash":"070212745f3d5cdcc7f0531388b455b52afc3ae9f3ce0db8e14617ac3e46534e","category":"Interdisciplinary"}